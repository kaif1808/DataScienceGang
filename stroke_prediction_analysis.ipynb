{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stroke Prediction Analysis\n",
    "\n",
    "This notebook implements a complete data science workflow for stroke prediction, addressing class imbalance and comparing multiple models including Random Forest, Logistic Regression, XGBoost, and a Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotnine import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_score, recall_score, f1_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "Loading the dataset using Polars. We handle potential parsing errors by increasing the schema inference length and specifying null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with robust error handling settings\n",
    "stroke_df = pl.read_csv(\n",
    "    \"healthcare-dataset-stroke-data.csv\", \n",
    "    null_values=[\"N/A\", \"\"],\n",
    "    infer_schema_length=10000\n",
    ")\n",
    "\n",
    "print(f\"Dataset shape: {stroke_df.shape}\")\n",
    "stroke_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning & Feature Engineering\n",
    "\n",
    "We perform the following steps:\n",
    "1.  Impute missing BMI values with the median.\n",
    "2.  Remove the single observation with \"Other\" gender.\n",
    "3.  Create binary encodings for categorical variables.\n",
    "4.  Engineer new features: Age groups, BMI categories, Glucose categories, and a composite Risk Score.\n",
    "5.  Cast the target variable to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "\n",
    "# 1. Load and Initial Filter\n",
    "# Fix: Added infer_schema_length to scan more rows and null_values to handle \"N/A\" strings\n",
    "df = pl.read_csv(\n",
    "    \"healthcare-dataset-stroke-data.csv\", \n",
    "    infer_schema_length=10000, \n",
    "    null_values=[\"N/A\"]\n",
    ")\n",
    "df = df.filter(pl.col(\"gender\") != \"Other\")\n",
    "\n",
    "# 2. Prepare Data for KNN Imputation\n",
    "# We use Pandas/Sklearn for this specific step as Polars lacks a native KNN Imputer.\n",
    "pandas_df = df.to_pandas()\n",
    "\n",
    "# Identify columns\n",
    "cat_cols = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "num_cols = ['age', 'avg_glucose_level', 'hypertension', 'heart_disease']\n",
    "target_impute = ['bmi']\n",
    "\n",
    "# A. Temporarily Encode Categoricals (Ordinal is fine for distance approximation)\n",
    "encoder = OrdinalEncoder()\n",
    "df_encoded = pandas_df.copy()\n",
    "df_encoded[cat_cols] = encoder.fit_transform(df_encoded[cat_cols])\n",
    "\n",
    "# B. Scale Data (Crucial for KNN so 'age' doesn't dominate 'glucose')\n",
    "scaler = StandardScaler()\n",
    "cols_to_scale = num_cols + target_impute\n",
    "df_encoded[cols_to_scale] = scaler.fit_transform(df_encoded[cols_to_scale])\n",
    "\n",
    "# C. Apply KNN Imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "# We impute on everything except ID and Stroke\n",
    "impute_data = df_encoded[cat_cols + num_cols + target_impute]\n",
    "imputed_matrix = imputer.fit_transform(impute_data)\n",
    "\n",
    "# D. Recover BMI\n",
    "# The imputer returns an array in the same order. We extract the last column (BMI),\n",
    "# inverse transform the scaling, and assign it back.\n",
    "imputed_bmi_scaled = imputed_matrix[:, -1].reshape(-1, 1)\n",
    "\n",
    "# Calculate mean/std manually from original pandas_df for inverse transform\n",
    "# (We do this because we fit the scaler on multiple columns, making standard inverse_transform tricky for just one column)\n",
    "bmi_mean = pandas_df['bmi'].mean()\n",
    "bmi_std = pandas_df['bmi'].std()\n",
    "final_bmi = (imputed_bmi_scaled * bmi_std) + bmi_mean\n",
    "\n",
    "# 3. Back to Polars for Feature Engineering\n",
    "# We inject the imputed BMI back into the original Polars DataFrame\n",
    "stroke_final = (\n",
    "    df\n",
    "    .with_columns(pl.Series(name=\"bmi\", values=final_bmi.flatten()))\n",
    "    \n",
    "    # --- Feature Engineering ---\n",
    "    \n",
    "    # 1. Binary Encodings\n",
    "    .with_columns(\n",
    "        pl.col(\"ever_married\").replace({\"Yes\": 1, \"No\": 0}).cast(pl.Int8).alias(\"ever_married_binary\"),\n",
    "        pl.col(\"Residence_type\").replace({\"Urban\": 1, \"Rural\": 0}).cast(pl.Int8).alias(\"residence_urban\"),\n",
    "        pl.col(\"gender\").replace({\"Male\": 1, \"Female\": 0}).cast(pl.Int8).alias(\"gender_male\"),\n",
    "        pl.col(\"hypertension\").cast(pl.Int8),\n",
    "        pl.col(\"heart_disease\").cast(pl.Int8),\n",
    "        pl.col(\"stroke\").cast(pl.Int8),\n",
    "    )\n",
    "    \n",
    "    # 2. Binning (Age Groups)\n",
    "    .with_columns(\n",
    "        pl.when(pl.col(\"age\") < 18).then(pl.lit(\"0-17\"))\n",
    "        .when(pl.col(\"age\") < 40).then(pl.lit(\"18-39\"))\n",
    "        .when(pl.col(\"age\") < 60).then(pl.lit(\"40-59\"))\n",
    "        .when(pl.col(\"age\") < 80).then(pl.lit(\"60-79\"))\n",
    "        .otherwise(pl.lit(\"80+\"))\n",
    "        .alias(\"age_group\")\n",
    "    )\n",
    "    \n",
    "    # 3. BMI Categories\n",
    "    .with_columns(\n",
    "        pl.when(pl.col(\"bmi\") < 18.5).then(pl.lit(\"Underweight\"))\n",
    "        .when(pl.col(\"bmi\") < 25).then(pl.lit(\"Normal\"))\n",
    "        .when(pl.col(\"bmi\") < 30).then(pl.lit(\"Overweight\"))\n",
    "        .otherwise(pl.lit(\"Obese\"))\n",
    "        .alias(\"bmi_category\")\n",
    "    )\n",
    "    \n",
    "    # 4. Glucose Categories\n",
    "    .with_columns(\n",
    "        pl.when(pl.col(\"avg_glucose_level\") < 100).then(pl.lit(\"Normal\"))\n",
    "        .when(pl.col(\"avg_glucose_level\") < 126).then(pl.lit(\"Prediabetic\"))\n",
    "        .otherwise(pl.lit(\"Diabetic\"))\n",
    "        .alias(\"glucose_category\")\n",
    "    )\n",
    "    \n",
    "    # 5. Risk Score Interaction\n",
    "    .with_columns(\n",
    "        (\n",
    "            pl.col(\"hypertension\") + \n",
    "            pl.col(\"heart_disease\") + \n",
    "            (pl.col(\"age\") >= 55).cast(pl.Int8) +\n",
    "            (pl.col(\"avg_glucose_level\") >= 126).cast(pl.Int8) +\n",
    "            (pl.col(\"bmi\") >= 30).cast(pl.Int8)\n",
    "        ).alias(\"risk_score\")\n",
    "    )\n",
    "    .drop(\"id\")\n",
    ")\n",
    "\n",
    "# Export for non-CV models / EDA\n",
    "stroke_final.write_csv(\"stroke_cleaned.csv\")\n",
    "print(\"Cleaned data exported with KNN imputation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CV Pipeline\n",
    "\n",
    "We split the data into training and testing sets, then apply scaling and one-hot encoding. Crucially, we apply SMOTE (Synthetic Minority Over-sampling Technique) only to the training data to address the class imbalance without causing data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Custom Feature Engineer for the Pipeline\n",
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # Add Age Group\n",
    "        X['age_group'] = pd.cut(X['age'], bins=[0,18,45,65,100], labels=['child','adult','senior','elderly'])\n",
    "        # Add Risk Interaction (Glucose * Age)\n",
    "        X['glucose_age_interaction'] = X['avg_glucose_level'] * X['age']\n",
    "        return X\n",
    "\n",
    "# 1. Prepare Data (Raw split)\n",
    "# We use the pandas version of the raw filtered data\n",
    "X = pandas_df.drop(['stroke', 'id'], axis=1)\n",
    "y = pandas_df['stroke']\n",
    "\n",
    "# 2. Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 3. Define Preprocessing (Impute -> Scale -> Encode)\n",
    "numeric_features = ['age', 'avg_glucose_level', 'bmi', 'glucose_age_interaction']\n",
    "categorical_features = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'age_group']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('imputer', KNNImputer(n_neighbors=5)) \n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# 4. Construct the Master CV Pipeline\n",
    "cv_pipeline = ImbPipeline(steps=[\n",
    "    ('feature_engineering', FeatureEngineer()),  # Creates columns\n",
    "    ('preprocessor', preprocessor),              # Handles NaNs, Scaling, Encoding\n",
    "    ('smote', SMOTE(random_state=42)),           # Resampling inside the fold\n",
    "    ('model', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# 5. Run CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(cv_pipeline, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "\n",
    "print(f\"CV ROC-AUC Scores: {scores}\")\n",
    "print(f\"Mean ROC-AUC: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training & Evaluation\n",
    "\n",
    "We train and compare three models: Random Forest, Logistic Regression, and XGBoost. All models are trained on the SMOTE-resampled training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 1. Define the Models (Same as your list)\n",
    "# Note: For Stacking, we keep cv=5 internal, but we will also cross-validate the whole stack externally (Nested CV).\n",
    "base_learners = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)),\n",
    "    ('lr', LogisticRegression(class_weight=\"balanced\", max_iter=1000, random_state=42))\n",
    "]\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight=\"balanced\", max_iter=1000, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, scale_pos_weight=5, random_state=42, eval_metric=\"logloss\"),\n",
    "    \"Stacking Classifier\": StackingClassifier(estimators=base_learners, final_estimator=LogisticRegression(), cv=5)\n",
    "}\n",
    "\n",
    "# 2. Define Scoring Metrics\n",
    "# We want to track all these metrics during CV\n",
    "scoring_metrics = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'recall': 'recall',\n",
    "    'precision': 'precision',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "# 3. The CV Loop\n",
    "cv_results_data = []\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"Starting Cross-Validation Pipeline...\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    \n",
    "    # Create a fresh pipeline for this specific model\n",
    "    # We inject the model into the 'classifier' step defined in the previous solution\n",
    "    current_pipeline = ImbPipeline(steps=[\n",
    "        ('engineer', FeatureEngineer()),      # Feature Engineering\n",
    "        ('preprocessor', preprocessor),       # Imputation & Scaling\n",
    "        ('smote', SMOTE(random_state=42)),    # SMOTE (Inside CV!)\n",
    "        ('classifier', model)                 # The specific model being tested\n",
    "    ])\n",
    "    \n",
    "    # Run Cross-Validation\n",
    "    # CRITICAL: We pass X_train, y_train (the raw data), NOT the resampled data.\n",
    "    # The pipeline handles the resampling for us.\n",
    "    scores = cross_validate(\n",
    "        current_pipeline, \n",
    "        X_train, \n",
    "        y_train, \n",
    "        cv=cv, \n",
    "        scoring=scoring_metrics,\n",
    "        n_jobs=-1  # Use all CPU cores\n",
    "    )\n",
    "    \n",
    "    # Store the MEAN score across all 5 folds\n",
    "    cv_results_data.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": scores['test_accuracy'].mean(),\n",
    "        \"Recall\": scores['test_recall'].mean(),\n",
    "        \"Precision\": scores['test_precision'].mean(),\n",
    "        \"F1 Score\": scores['test_f1'].mean(),\n",
    "        \"ROC-AUC\": scores['test_roc_auc'].mean()\n",
    "    })\n",
    "\n",
    "# 4. Display Comparison\n",
    "results_df = pd.DataFrame(cv_results_data)\n",
    "print(\"\\n=== Cross-Validation Performance (Mean of 5 Folds) ===\")\n",
    "print(results_df.round(4).sort_values(by='ROC-AUC', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Elastic Net Grid Search\n",
    "\n",
    "We perform a grid search to optimize the Logistic Regression model using Elastic Net regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 1. Setup Pipeline and Grid Search\n",
    "# ---------------------------------------------------------\n",
    "# We define the full pipeline including SMOTE\n",
    "lr_pipeline = ImbPipeline(steps=[\n",
    "    ('engineer', FeatureEngineer()),  # Our custom class from before\n",
    "    ('preprocessor', preprocessor),   # The ColumnTransformer from before\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', LogisticRegression(\n",
    "        penalty=\"elasticnet\",\n",
    "        solver=\"saga\",\n",
    "        max_iter=2000,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Note the double underscore prefix 'classifier__' to target the step\n",
    "param_grid = {\n",
    "    \"classifier__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"classifier__l1_ratio\": [0, 0.25, 0.5, 0.75, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    lr_pipeline,\n",
    "    param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Running Grid Search on Pipeline...\")\n",
    "# CRITICAL: Pass raw X_train/y_train. The pipeline handles the rest.\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 2. Extract Best Model and Evaluate\n",
    "# ---------------------------------------------------------\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(f\"\\n=== BEST MODEL SELECTED ===\")\n",
    "print(f\"Parameters: {best_params}\")\n",
    "\n",
    "# Generate Predictions (Pass raw X_test, pipeline handles transformation)\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "y_proba = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate Metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n=== TEST SET METRICS ===\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"ROC-AUC:   {auc:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# 3. Generate Coefficient Path Diagram\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\nGenerating Coefficient Path...\")\n",
    "\n",
    "# We need to manually preprocess the data once so we can loop through C values quickly\n",
    "# (Running the full pipeline 30 times would be slow)\n",
    "\n",
    "# A. Extract steps from the fitted best pipeline\n",
    "engineer_step = best_pipeline.named_steps['engineer']\n",
    "preprocessor_step = best_pipeline.named_steps['preprocessor']\n",
    "smote_step = best_pipeline.named_steps['smote']\n",
    "\n",
    "# B. Transform X_train to the state the classifier sees\n",
    "X_eng = engineer_step.transform(X_train)         # Add features\n",
    "X_scaled = preprocessor_step.transform(X_eng)    # Scale/Encode\n",
    "X_resampled, y_resampled = smote_step.fit_resample(X_scaled, y_train) # Apply SMOTE\n",
    "\n",
    "# C. Get Feature Names\n",
    "try:\n",
    "    feature_names = preprocessor_step.get_feature_names_out()\n",
    "except:\n",
    "    feature_names = [f\"Feature {i}\" for i in range(X_resampled.shape[1])]\n",
    "\n",
    "Cs = param_grid['classifier__C']\n",
    "best_l1 = best_params['classifier__l1_ratio']\n",
    "coeffs = []\n",
    "\n",
    "# Loop through C values using just the classifier part\n",
    "for c in Cs:\n",
    "    clf = LogisticRegression(\n",
    "        penalty=\"elasticnet\",\n",
    "        solver=\"saga\",\n",
    "        C=c,\n",
    "        l1_ratio=best_l1,\n",
    "        max_iter=2000,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "    # Fit on the pre-processed, resampled data\n",
    "    clf.fit(X_resampled, y_resampled)\n",
    "    coeffs.append(clf.coef_.ravel())\n",
    "\n",
    "coeffs = np.array(coeffs)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(coeffs.shape[1]):\n",
    "    plt.plot(np.log10(Cs), coeffs[:, i], marker='o', label=feature_names[i])\n",
    "\n",
    "best_c = best_params['classifier__C']\n",
    "plt.axvline(x=np.log10(best_c), color='black', linestyle='--', label=f\"Best C ({best_c})\")\n",
    "\n",
    "plt.title(f\"Coefficient Path (Elastic Net, l1_ratio={best_l1})\")\n",
    "plt.xlabel(\"log10(C) - Inverse Regularization Strength\")\n",
    "plt.ylabel(\"Coefficient Value\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left') \n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Standard Heatmap\n",
    "# ---------------------------------------------------------\n",
    "results_pd = pd.DataFrame(grid_search.cv_results_)\n",
    "pivot_table = results_pd.pivot(index=\"param_classifier__C\", columns=\"param_classifier__l1_ratio\", values=\"mean_test_score\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.heatmap(pivot_table, annot=True, fmt=\".4f\", cmap=\"viridis\")\n",
    "plt.title(\"Grid Search AUC Performance\")\n",
    "plt.xlabel(\"L1 Ratio\")\n",
    "plt.ylabel(\"C\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Lasso Coefficient Analysis\n",
    "\n",
    "We analyze the coefficients of the best Elastic Net model to see which features were shrunk to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# --- SHAP ANALYSIS (Suggestion 4) ---\n",
    "# We use a Random Forest model for the explanation as it handles non-linearities well.\n",
    "# We retrain a fresh instance on the processed data to ensure the explainer has full access.\n",
    "\n",
    "print(\"Training Explainer Model (Random Forest)...\")\n",
    "rf_explainer = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_explainer.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Initialize SHAP Tree Explainer\n",
    "explainer = shap.TreeExplainer(rf_explainer)\n",
    "\n",
    "# Calculate SHAP values for the test set\n",
    "# We take a sample of the test set if it's too large, but here it's small enough.\n",
    "shap_values = explainer.shap_values(X_test_processed)\n",
    "\n",
    "# Get feature names for the plot\n",
    "# We need to combine numeric, binary, and one-hot encoded categorical names\n",
    "cat_feature_names = list(preprocessor.named_transformers_[\"cat\"].get_feature_names_out(categorical_features))\n",
    "# Note: We added interaction terms in the previous step, so we need to ensure feature names align.\n",
    "# The 'numeric_features' list in Cell 5 needs to match what was used in 'ColumnTransformer'.\n",
    "# Assuming 'preprocessor' was fitted on the DataFrame that INCLUDED the interaction terms:\n",
    "feature_names_all = numeric_features + binary_features + cat_feature_names\n",
    "\n",
    "print(\"Generating SHAP Summary Plot...\")\n",
    "# Summary plot for the positive class (Stroke = 1)\n",
    "shap.summary_plot(shap_values[1], X_test_processed, feature_names=feature_names_all)\n",
    "\n",
    "# Optional: Force plot for a single high-risk prediction\n",
    "# shap.force_plot(explainer.expected_value[1], shap_values[1][0,:], X_test_processed[0,:], feature_names=feature_names_all, matplotlib=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Neural Network\n",
    "\n",
    "We implement a binary classification neural network using TensorFlow/Keras. We check for Apple Metal (MPS) acceleration availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, f1_score, confusion_matrix, precision_recall_curve, auc\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Manual Preprocessing for PyTorch\n",
    "# (Since we can't put a PyTorch model directly into an sklearn Pipeline easily)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# A. Feature Engineering\n",
    "fe = FeatureEngineer()\n",
    "X_train_eng = fe.fit_transform(X_train)\n",
    "X_test_eng = fe.transform(X_test)\n",
    "\n",
    "# B. Scaling & Imputation (Fit on Train, Transform Test)\n",
    "X_train_processed = preprocessor.fit_transform(X_train_eng)\n",
    "X_test_processed = preprocessor.transform(X_test_eng)\n",
    "\n",
    "# C. SMOTE (Only on Training Data)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. PyTorch Setup\n",
    "# ---------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Check for MPS (Apple Silicon)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "print(f\"Running on device: {device}\")\n",
    "\n",
    "# Convert to Tensors\n",
    "X_train_tensor = torch.tensor(X_train_resampled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_resampled.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test_processed, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True) # Increased batch size for stability\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Define Model\n",
    "# ---------------------------------------------------------\n",
    "class StrokeClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(StrokeClassifier, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(32, 1), # Output layer\n",
    "            # No Sigmoid here because we use BCEWithLogitsLoss\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "model = StrokeClassifier(input_dim=X_train_resampled.shape[1]).to(device)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Weighted Loss & Optimizer\n",
    "# ---------------------------------------------------------\n",
    "# We calculate weight based on the resampled data (though it is balanced now, \n",
    "# sometimes adding a small weight helps focus learning).\n",
    "pos_weight_value = torch.tensor([1.0]).to(device) # SMOTE balanced it, so roughly 1:1\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_value)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. Training Loop\n",
    "# ---------------------------------------------------------\n",
    "epochs = 100\n",
    "patience = 15\n",
    "best_val_auc = 0\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "history = {'loss': [], 'val_auc': [], 'val_recall': []}\n",
    "\n",
    "print(f\"\\nStarting Training (Max {epochs} epochs)...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test_gpu = X_test_tensor.to(device)\n",
    "        test_logits = model(X_test_gpu)\n",
    "        test_probs = torch.sigmoid(test_logits).cpu().numpy()\n",
    "        \n",
    "        # Calculate Val AUC\n",
    "        val_auc = roc_auc_score(y_test, test_probs)\n",
    "        val_recall = recall_score(y_test, (test_probs > 0.5).astype(int))\n",
    "\n",
    "    history['loss'].append(avg_loss)\n",
    "    history['val_auc'].append(val_auc)\n",
    "    history['val_recall'].append(val_recall)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}/{epochs} | Loss: {avg_loss:.4f} | Val AUC: {val_auc:.4f} | Recall(0.5): {val_recall:.4f}\")\n",
    "    \n",
    "    # Early Stopping\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        patience_counter = 0\n",
    "        best_model_state = model.state_dict()\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            model.load_state_dict(best_model_state)\n",
    "            break\n",
    "\n",
    "# Load best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 6. Visualization\n",
    "# ---------------------------------------------------------\n",
    "# A. Plot History\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['loss'], label='Train Loss')\n",
    "plt.title('Training Loss')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['val_auc'], label='Val AUC', color='green')\n",
    "plt.title('Validation ROC-AUC')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['val_recall'], label='Val Recall', color='orange')\n",
    "plt.title('Validation Recall')\n",
    "plt.show()\n",
    "\n",
    "# B. Multi-Threshold Analysis\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    final_logits = model(X_test_tensor.to(device))\n",
    "    final_probs = torch.sigmoid(final_logits).cpu().numpy()\n",
    "\n",
    "# Metric Calculations\n",
    "precision_curve, recall_curve, thresholds = precision_recall_curve(y_test, final_probs)\n",
    "f1_scores = 2 * (precision_curve * recall_curve) / (precision_curve + recall_curve + 1e-10)\n",
    "best_f1_idx = np.argmax(f1_scores)\n",
    "best_f1_thresh = thresholds[best_f1_idx]\n",
    "\n",
    "# 90% Recall Threshold\n",
    "recall_target_idx = np.where(recall_curve >= 0.90)[0][-1]\n",
    "high_recall_thresh = thresholds[recall_target_idx]\n",
    "\n",
    "def get_metrics(probs, y_true, thresh):\n",
    "    preds = (probs > thresh).astype(int)\n",
    "    cm = confusion_matrix(y_true, preds)\n",
    "    return {\n",
    "        \"Threshold\": f\"{thresh:.4f}\",\n",
    "        \"Recall\": recall_score(y_true, preds),\n",
    "        \"Precision\": precision_score(y_true, preds),\n",
    "        \"Accuracy\": (preds == y_true.reshape(-1)).mean(),\n",
    "        \"F1\": f1_score(y_true, preds),\n",
    "        \"TP\": cm[1,1], \"FN\": cm[1,0], \"FP\": cm[0,1]\n",
    "    }\n",
    "\n",
    "results = [\n",
    "    get_metrics(final_probs, y_test, 0.5),\n",
    "    get_metrics(final_probs, y_test, best_f1_thresh),\n",
    "    get_metrics(final_probs, y_test, high_recall_thresh)\n",
    "]\n",
    "\n",
    "df_results = pd.DataFrame(results, index=[\"Standard (0.5)\", \"Best F1 Balance\", \"High Recall (~90%)\"])\n",
    "print(\"\\n=== COMPARATIVE RESULTS ===\")\n",
    "print(df_results.to_string())\n",
    "\n",
    "# Plot Confusion Matrix for Best F1\n",
    "best_preds = (final_probs > best_f1_thresh).astype(int)\n",
    "cm = confusion_matrix(y_test, best_preds)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f'Confusion Matrix (Best F1 Threshold: {best_f1_thresh:.4f})')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
