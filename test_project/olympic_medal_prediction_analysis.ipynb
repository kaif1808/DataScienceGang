{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e45ff7",
   "metadata": {},
   "source": [
    "# Predicting Olympic Medal Success\n",
    "Using Socioeconomic Indicators to Forecast Summer and Winter Olympic Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2222c792",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading\n",
    "Before running this notebook, ensure the following R packages are installed:\n",
    "- `tidyverse`\n",
    "- `data.table`\n",
    "- `glmnet`\n",
    "- `randomForest`\n",
    "- `patchwork`\n",
    "\n",
    "You can install any missing packages with:\n",
    "```r\n",
    "install.packages(c(\"tidyverse\", \"data.table\", \"glmnet\", \"randomForest\", \"patchwork\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41e39ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(data.table)\n",
    "library(glmnet)\n",
    "library(randomForest)\n",
    "library(patchwork)\n",
    "\n",
    "final_data <- fread(\"final_medals_model_input.csv\")\n",
    "glimpse(final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b768e3f0",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c729270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Global development trends\n",
    "final_data |>\n",
    "  group_by(year) |>\n",
    "  summarise(\n",
    "    avg_gdp_per_capita = mean(GDP_per_capita, na.rm = TRUE),\n",
    "    avg_life_expectancy = mean(life_expectancy_total_years, na.rm = TRUE),\n",
    "    avg_internet_access = mean(internet_access_percent, na.rm = TRUE)\n",
    "  ) |>\n",
    "  pivot_longer(-year) |>\n",
    "  ggplot(aes(year, value)) +\n",
    "  geom_line(color = \"steelblue\", linewidth = 1) +\n",
    "  geom_point(color = \"steelblue\", size = 1.5) +\n",
    "  facet_wrap(~name, scales = \"free_y\", ncol = 1,\n",
    "             labeller = labeller(name = c(\n",
    "               avg_gdp_per_capita = \"Average GDP per Capita\",\n",
    "               avg_life_expectancy = \"Average Life Expectancy\",\n",
    "               avg_internet_access = \"Average Internet Access (%)\"\n",
    "             ))) +\n",
    "  labs(title = \"Global Development Trends\", x = \"Year\", y = \"Value\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# 2.2 Medal distribution (top 20 countries)\n",
    "medal_counts <- final_data |>\n",
    "  group_by(country_noc) |>\n",
    "  summarise(\n",
    "    total_gold = sum(gold, na.rm = TRUE),\n",
    "    total_silver = sum(silver, na.rm = TRUE),\n",
    "    total_bronze = sum(bronze, na.rm = TRUE),\n",
    "    total_medals = sum(total, na.rm = TRUE)\n",
    "  ) |>\n",
    "  arrange(desc(total_medals))\n",
    "\n",
    "medal_counts |>\n",
    "  slice_head(n = 20) |>\n",
    "  pivot_longer(total_gold:total_bronze, names_to = \"medal\", values_to = \"count\") |>\n",
    "  mutate(medal = factor(medal, levels = c(\"total_gold\", \"total_silver\", \"total_bronze\"),\n",
    "                        labels = c(\"Gold\", \"Silver\", \"Bronze\"))) |>\n",
    "  ggplot(aes(reorder(country_noc, total_medals), count, fill = medal)) +\n",
    "  geom_col() +\n",
    "  coord_flip() +\n",
    "  scale_fill_manual(values = c(\"Gold\" = \"#FFD700\", \"Silver\" = \"#C0C0C0\", \"Bronze\" = \"#CD7F32\")) +\n",
    "  labs(title = \"Top 20 Medal-Winning Countries (1996-2024)\",\n",
    "       x = \"Country\", y = \"Number of Medals\", fill = \"Medal Type\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# 2.3 GDP vs medals relationship\n",
    "gdp_medals <- final_data |>\n",
    "  group_by(country_noc) |>\n",
    "  summarise(\n",
    "    avg_gdp_per_capita = mean(GDP_per_capita, na.rm = TRUE),\n",
    "    total_medals = sum(total, na.rm = TRUE),\n",
    "    avg_population = mean(Population, na.rm = TRUE)\n",
    "  ) |>\n",
    "  drop_na()\n",
    "\n",
    "ggplot(gdp_medals, aes(avg_gdp_per_capita, total_medals)) +\n",
    "  geom_point(aes(size = avg_population), alpha = 0.6, color = \"steelblue\") +\n",
    "  geom_smooth(method = \"lm\", se = TRUE, color = \"darkred\", linetype = \"dashed\") +\n",
    "  scale_x_continuous(labels = scales::comma) +\n",
    "  scale_size_continuous(labels = scales::comma) +\n",
    "  labs(title = \"GDP per Capita vs Total Medals\", x = \"Average GDP per Capita (USD)\",\n",
    "       y = \"Total Medals (1996-2024)\", size = \"Avg Population\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1782c437",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ba338",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_fe_data <- function(data) {\n",
    "  data |>\n",
    "    arrange(country_noc, year) |>\n",
    "    group_by(country_noc) |>\n",
    "    mutate(\n",
    "      gdp_pop_interaction = GDP_per_capita * log(Population + 1),\n",
    "      development_index = (life_expectancy_total_years / 100) * internet_access_percent,\n",
    "      gdp_squared = GDP_per_capita^2,\n",
    "      population_log = log(Population + 1),\n",
    "      medals_lag1 = lag(total, 1),\n",
    "      medals_lag2 = lag(total, 2),\n",
    "      medals_rolling_avg = (lag(total, 1) + lag(total, 2) + lag(total, 3)) / 3,\n",
    "      gdp_growth = (GDP_per_capita - lag(GDP_per_capita, 1)) / (lag(GDP_per_capita, 1) + 0.001),\n",
    "      internet_growth = internet_access_percent - lag(internet_access_percent, 1),\n",
    "      govt_gdp_ratio = Government_Spending / (GDP_per_capita * Population + 1),\n",
    "      military_gdp_ratio = mil_expenditure_percent / 100,\n",
    "      high_population = as.integer(Population > median(Population, na.rm = TRUE)),\n",
    "      high_gdp = as.integer(GDP_per_capita > median(GDP_per_capita, na.rm = TRUE)),\n",
    "      infra_score = (elec_access_percent + internet_access_percent + mobile_sub_per100) / 3\n",
    "    ) |>\n",
    "    ungroup()\n",
    "}\n",
    "\n",
    "model_data_fe <- final_data |>\n",
    "  select(year, country_noc, total,\n",
    "         GDP_per_capita, Population, life_expectancy_total_years,\n",
    "         internet_access_percent, elec_access_percent, pol_stability_estimate,\n",
    "         Government_Spending, mil_expenditure_percent, Labour_Force_Female,\n",
    "         literacy_rate_adult_total_pct, Inflation_Rate, Unemployment_Rate,\n",
    "         contraceptive_percent_married, energy_oil_equiv_kg_per_capita,\n",
    "         mobile_sub_per100, urban_growth, gross_cap_form_gdp, tax_revenue_gdp) |>\n",
    "  create_fe_data()\n",
    "\n",
    "glimpse(model_data_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f3a1fd",
   "metadata": {},
   "source": [
    "## 4. Penalised Regression Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9b3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_splits <- list(\n",
    "  split1 = list(train_years = 1996:2008, test_years = 2010:2012),\n",
    "  split2 = list(train_years = 1996:2012, test_years = 2014:2016),\n",
    "  split3 = list(train_years = 1996:2016, test_years = 2018:2020),\n",
    "  split4 = list(train_years = 1996:2020, test_years = 2022:2024)\n",
    ")\n",
    "\n",
    "prepare_matrices_fe <- function(data, train_years, test_years) {\n",
    "  train_data <- data |> filter(year %in% train_years)\n",
    "  test_data <- data |> filter(year %in% test_years)\n",
    "  predictor_cols <- setdiff(names(data), c(\"year\", \"country_noc\", \"total\"))\n",
    "  train_means <- train_data |>\n",
    "    summarise(across(all_of(predictor_cols), ~ifelse(is.nan(mean(., na.rm = TRUE)), 0, mean(., na.rm = TRUE))))\n",
    "  X_train <- train_data |>\n",
    "    select(all_of(predictor_cols)) |>\n",
    "    mutate(across(everything(), ~{\n",
    "      col_mean <- train_means[[cur_column()]]\n",
    "      ifelse(is.na(.) | is.infinite(.), col_mean, .)\n",
    "    })) |>\n",
    "    as.matrix()\n",
    "  X_test <- test_data |>\n",
    "    select(all_of(predictor_cols)) |>\n",
    "    mutate(across(everything(), ~{\n",
    "      col_mean <- train_means[[cur_column()]]\n",
    "      ifelse(is.na(.) | is.infinite(.), col_mean, .)\n",
    "    })) |>\n",
    "    as.matrix()\n",
    "  X_train[is.na(X_train) | is.infinite(X_train)] <- 0\n",
    "  X_test[is.na(X_test) | is.infinite(X_test)] <- 0\n",
    "  list(\n",
    "    X_train = X_train,\n",
    "    y_train = train_data$total,\n",
    "    X_test = X_test,\n",
    "    y_test = test_data$total,\n",
    "    n_train = nrow(train_data),\n",
    "    n_test = nrow(test_data)\n",
    "  )\n",
    "}\n",
    "\n",
    "run_penalised_models <- function(data, splits) {\n",
    "  map(splits, ~{\n",
    "    mats <- prepare_matrices_fe(data, .x$train_years, .x$test_years)\n",
    "    cv_lasso <- cv.glmnet(mats$X_train, mats$y_train, alpha = 1, nfolds = 5)\n",
    "    cv_enet <- cv.glmnet(mats$X_train, mats$y_train, alpha = 0.5, nfolds = 5)\n",
    "    tibble(\n",
    "      train_years = paste(range(.x$train_years), collapse = \"-\"),\n",
    "      test_years = paste(range(.x$test_years), collapse = \"-\"),\n",
    "      lasso_rmse = sqrt(mean((predict(cv_lasso, mats$X_test, s = \"lambda.min\") - mats$y_test)^2)),\n",
    "      lasso_r2 = cor(predict(cv_lasso, mats$X_test, s = \"lambda.min\"), mats$y_test)^2,\n",
    "      enet_rmse = sqrt(mean((predict(cv_enet, mats$X_test, s = \"lambda.min\") - mats$y_test)^2)),\n",
    "      enet_r2 = cor(predict(cv_enet, mats$X_test, s = \"lambda.min\"), mats$y_test)^2,\n",
    "      lasso_model = list(cv_lasso),\n",
    "      enet_model = list(cv_enet)\n",
    "    )\n",
    "  }) |> bind_rows()\n",
    "}\n",
    "\n",
    "pen_results <- run_penalised_models(model_data_fe, temporal_splits)\n",
    "pen_results |>\n",
    "  select(train_years, test_years, lasso_rmse, lasso_r2, enet_rmse, enet_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda43eec",
   "metadata": {},
   "source": [
    "### 4.1 Coefficient Path Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182a3285",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coefficient_paths <- function(cv_model, title) {\n",
    "  plot(cv_model$glmnet.fit, xvar = \"lambda\", label = TRUE)\n",
    "  title(main = title)\n",
    "}\n",
    "\n",
    "par(mfrow = c(2, 2))\n",
    "walk2(pen_results$lasso_model, seq_along(pen_results$lasso_model), ~plot_coefficient_paths(.x, paste0(\"Lasso Paths - Split \", .y)))\n",
    "par(mfrow = c(2, 2))\n",
    "walk2(pen_results$enet_model, seq_along(pen_results$enet_model), ~plot_coefficient_paths(.x, paste0(\"Elastic Net Paths - Split \", .y)))\n",
    "par(mfrow = c(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e46f4b6",
   "metadata": {},
   "source": [
    "### 4.2 Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6106d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_results |>\n",
    "  select(test_years, lasso_rmse, enet_rmse, lasso_r2, enet_r2) |>\n",
    "  pivot_longer(-test_years) |>\n",
    "  mutate(metric = ifelse(str_detect(name, \"rmse\"), \"RMSE\", \"R²\"),\n",
    "         model = case_when(str_detect(name, \"lasso\") ~ \"Lasso\",\n",
    "                            TRUE ~ \"Elastic Net\")) |>\n",
    "  ggplot(aes(test_years, value, color = model, group = model)) +\n",
    "  geom_point(size = 3) +\n",
    "  geom_line(linewidth = 1.1) +\n",
    "  facet_wrap(~metric, scales = \"free_y\", ncol = 1) +\n",
    "  labs(title = \"Penalised Regression Performance\",\n",
    "       x = \"Test Period\", y = \"Value\", color = \"Model\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1059679d",
   "metadata": {},
   "source": [
    "## 5. Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece5ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_rf <- model_data_fe |>\n",
    "  mutate(\n",
    "    medal_category = case_when(\n",
    "      total == 0 ~ \"No Medals\",\n",
    "      total <= 5 ~ \"Low (1-5)\",\n",
    "      total <= 20 ~ \"Medium (6-20)\",\n",
    "      total <= 50 ~ \"High (21-50)\",\n",
    "      TRUE ~ \"Very High (>50)\"\n",
    "    ),\n",
    "    medal_category = factor(medal_category,\n",
    "                           levels = c(\"No Medals\", \"Low (1-5)\", \"Medium (6-20)\",\n",
    "                                      \"High (21-50)\", \"Very High (>50)\"))\n",
    "  )\n",
    "\n",
    "split4 <- temporal_splits[[4]]\n",
    "train_rf <- model_data_rf |> filter(year %in% split4$train_years)\n",
    "test_rf <- model_data_rf |> filter(year %in% split4$test_years)\n",
    "predictor_cols_rf <- setdiff(names(model_data_rf), c(\"year\", \"country_noc\", \"total\", \"medal_category\"))\n",
    "\n",
    "prep_rf <- function(df) {\n",
    "  df |>\n",
    "    select(all_of(c(predictor_cols_rf, \"medal_category\"))) |>\n",
    "    mutate(across(where(is.numeric), ~ifelse(is.na(.) | is.infinite(.), median(., na.rm = TRUE), .))) |>\n",
    "    drop_na()\n",
    "}\n",
    "\n",
    "train_rf_clean <- prep_rf(train_rf)\n",
    "test_rf_clean <- prep_rf(test_rf)\n",
    "\n",
    "set.seed(123)\n",
    "rf_model <- randomForest(medal_category ~ ., data = train_rf_clean,\n",
    "                         ntree = 500, mtry = floor(sqrt(length(predictor_cols_rf))),\n",
    "                         importance = TRUE)\n",
    "\n",
    "rf_pred <- predict(rf_model, test_rf_clean)\n",
    "conf_matrix <- table(Predicted = rf_pred, Actual = test_rf_clean$medal_category)\n",
    "conf_matrix\n",
    "\n",
    "accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)\n",
    "accuracy\n",
    "\n",
    "importance_df <- data.frame(\n",
    "  Feature = rownames(importance(rf_model)),\n",
    "  MeanDecreaseAccuracy = importance(rf_model)[, \"MeanDecreaseAccuracy\"]\n",
    ") |>\n",
    "  arrange(desc(MeanDecreaseAccuracy)) |>\n",
    "  slice_head(n = 15)\n",
    "\n",
    "ggplot(importance_df, aes(reorder(Feature, MeanDecreaseAccuracy), MeanDecreaseAccuracy)) +\n",
    "  geom_col(fill = \"steelblue\") +\n",
    "  coord_flip() +\n",
    "  labs(title = \"Random Forest Feature Importance\", x = \"Feature\", y = \"Mean Decrease in Accuracy\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161acb57",
   "metadata": {},
   "source": [
    "## 6. Stacked Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a51e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_split <- prepare_matrices_fe(model_data_fe, split4$train_years, split4$test_years)\n",
    "lasso_model_final <- pen_results$lasso_model[[4]]\n",
    "lasso_pred <- as.vector(predict(lasso_model_final, final_split$X_test, s = \"lambda.min\"))\n",
    "\n",
    "rf_prob <- predict(rf_model, test_rf_clean, type = \"prob\")\n",
    "class_midpoints <- c(0, 3, 13, 35.5, 75)\n",
    "rf_continuous <- as.vector(as.matrix(rf_prob) %*% class_midpoints)\n",
    "actual_counts <- final_split$y_test[seq_along(rf_continuous)]\n",
    "\n",
    "meta_df <- tibble(lasso_pred = lasso_pred[seq_along(rf_continuous)],\n",
    "                  rf_pred = rf_continuous,\n",
    "                  actual = actual_counts)\n",
    "\n",
    "meta_model <- lm(actual ~ lasso_pred + rf_pred, data = meta_df)\n",
    "meta_weights <- broom::tidy(meta_model)\n",
    "meta_weights\n",
    "\n",
    "ensemble_pred <- pmax(0, predict(meta_model, meta_df))\n",
    "\n",
    "calc_metrics <- function(pred, actual) list(\n",
    "  rmse = sqrt(mean((pred - actual)^2)),\n",
    "  mae = mean(abs(pred - actual)),\n",
    "  r2 = cor(pred, actual)^2\n",
    ")\n",
    "\n",
    "metrics <- tibble(\n",
    "  Model = c(\"Lasso (FE)\", \"Random Forest\", \"Stacked Ensemble\"),\n",
    "  bind_rows(calc_metrics(lasso_pred[seq_along(rf_continuous)], actual_counts),\n",
    "            calc_metrics(rf_continuous, actual_counts),\n",
    "            calc_metrics(ensemble_pred, actual_counts))\n",
    ")\n",
    "metrics\n",
    "\n",
    "pred_df <- tibble(\n",
    "  Actual = actual_counts,\n",
    "  `Lasso (FE)` = lasso_pred[seq_along(rf_continuous)],\n",
    "  `Random Forest` = rf_continuous,\n",
    "  `Stacked Ensemble` = ensemble_pred\n",
    ") |>\n",
    "  pivot_longer(-Actual, names_to = \"Model\", values_to = \"Predicted\")\n",
    "\n",
    "ggplot(pred_df, aes(Actual, Predicted, color = Model)) +\n",
    "  geom_point(alpha = 0.5) +\n",
    "  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +\n",
    "  facet_wrap(~Model) +\n",
    "  labs(title = \"Predicted vs Actual (2022-2024)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c55e0",
   "metadata": {},
   "source": [
    "## 7. Summer vs Winter Olympics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4403ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_olympics <- final_data |>\n",
    "  mutate(\n",
    "    olympic_type = case_when(\n",
    "      year %in% c(1998, 2002, 2006, 2010, 2014, 2018, 2022) ~ \"Winter\",\n",
    "      year %in% c(1996, 2000, 2004, 2008, 2012, 2016, 2020, 2024) ~ \"Summer\",\n",
    "      TRUE ~ NA_character_\n",
    "    )\n",
    "  ) |>\n",
    "  filter(!is.na(olympic_type))\n",
    "\n",
    "summer_data <- final_data_olympics |>\n",
    "  filter(olympic_type == \"Summer\") |>\n",
    "  create_fe_data()\n",
    "winter_data <- final_data_olympics |>\n",
    "  filter(olympic_type == \"Winter\") |>\n",
    "  create_fe_data()\n",
    "\n",
    "summer_splits <- list(\n",
    "  split1 = list(train_years = c(1996, 2000, 2004, 2008, 2012), test_years = 2016),\n",
    "  split2 = list(train_years = c(1996, 2000, 2004, 2008, 2012, 2016), test_years = 2020),\n",
    "  split3 = list(train_years = c(1996, 2000, 2004, 2008, 2012, 2016, 2020), test_years = 2024)\n",
    ")\n",
    "winter_splits <- list(\n",
    "  split1 = list(train_years = c(1998, 2002, 2006, 2010), test_years = 2014),\n",
    "  split2 = list(train_years = c(1998, 2002, 2006, 2010, 2014), test_years = 2018),\n",
    "  split3 = list(train_years = c(1998, 2002, 2006, 2010, 2014, 2018), test_years = 2022)\n",
    ")\n",
    "\n",
    "summer_results <- run_penalised_models(summer_data, summer_splits)\n",
    "winter_results <- run_penalised_models(winter_data, winter_splits)\n",
    "\n",
    "comparison_sw <- bind_rows(\n",
    "  summer_results |>\n",
    "    mutate(Olympic_Type = \"Summer\", Split = row_number()),\n",
    "  winter_results |>\n",
    "    mutate(Olympic_Type = \"Winter\", Split = row_number())\n",
    ") |>\n",
    "  select(Olympic_Type, Split, test_years, lasso_rmse, lasso_r2)\n",
    "\n",
    "comparison_sw\n",
    "\n",
    "comparison_sw |>\n",
    "  ggplot(aes(Split, lasso_r2, color = Olympic_Type)) +\n",
    "  geom_point(size = 4) + geom_line(linewidth = 1.2) +\n",
    "  labs(title = \"Summer vs Winter: R² by Split\", x = \"Split\", y = \"R²\") +\n",
    "  theme_minimal()\n",
    "\n",
    "comparison_sw |>\n",
    "  ggplot(aes(Split, lasso_rmse, color = Olympic_Type)) +\n",
    "  geom_point(size = 4) + geom_line(linewidth = 1.2) +\n",
    "  labs(title = \"Summer vs Winter: RMSE by Split\", x = \"Split\", y = \"RMSE\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e2a554",
   "metadata": {},
   "source": [
    "### 7.1 Top Countries & Feature Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db6c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_top <- summer_data |>\n",
    "  group_by(country_noc) |>\n",
    "  summarise(avg_medals = mean(total, na.rm = TRUE)) |>\n",
    "  arrange(desc(avg_medals)) |>\n",
    "  slice_head(n = 10)\n",
    "\n",
    "winter_top <- winter_data |>\n",
    "  group_by(country_noc) |>\n",
    "  summarise(avg_medals = mean(total, na.rm = TRUE)) |>\n",
    "  arrange(desc(avg_medals)) |>\n",
    "  slice_head(n = 10)\n",
    "\n",
    "summer_top\n",
    "winter_top\n",
    "\n",
    "summer_coef <- coef(summer_results$lasso_model[[3]]$glmnet.fit, s = summer_results$lasso_model[[3]]$lambda.min)\n",
    "winter_coef <- coef(winter_results$lasso_model[[3]]$glmnet.fit, s = winter_results$lasso_model[[3]]$lambda.min)\n",
    "\n",
    "coef_compare <- full_join(\n",
    "  tibble(Feature = rownames(summer_coef), Summer = as.vector(summer_coef)),\n",
    "  tibble(Feature = rownames(winter_coef), Winter = as.vector(winter_coef)),\n",
    "  by = \"Feature\"\n",
    ") |>\n",
    "  filter(Feature != \"(Intercept)\") |>\n",
    "  replace_na(list(Summer = 0, Winter = 0)) |>\n",
    "  mutate(Total = abs(Summer) + abs(Winter)) |>\n",
    "  arrange(desc(Total)) |>\n",
    "  slice_head(n = 12) |>\n",
    "  pivot_longer(Summer:Winter, names_to = \"Type\", values_to = \"Coefficient\")\n",
    "\n",
    "ggplot(coef_compare, aes(reorder(Feature, abs(Coefficient)), Coefficient, fill = Type)) +\n",
    "  geom_col(position = \"dodge\") +\n",
    "  coord_flip() +\n",
    "  labs(title = \"Feature Importance: Summer vs Winter\", x = \"Feature\", y = \"Coefficient\") +\n",
    "  scale_fill_manual(values = c(\"Summer\" = \"#E74C3C\", \"Winter\" = \"#3498DB\")) +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fb5a40",
   "metadata": {},
   "source": [
    "## 8. Key Findings & Next Steps\n",
    "- Historical Olympic performance (lagged medals) is the single strongest predictor.\n",
    "- Government spending ratios and population size drive Summer success, while Winter success depends more on military spending ratios and political stability.\n",
    "- Stacked ensemble (81% Lasso / 19% RF) achieves the best predictions with RMSE ≈ 3.1 medals and R² ≈ 0.92.\n",
    "- Winter Olympics have fewer medals, yielding lower absolute errors but slightly lower R².\n",
    "\n",
    "### Future Improvements\n",
    "- Incorporate climate/geographic features to refine Winter predictions.\n",
    "- Add host-country indicators to capture home advantage.\n",
    "- Build sport-specific models or forecast per-discipline medal counts.\n",
    "- Generate prediction intervals for upcoming Olympics."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "r"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
